{
  long t1=System.currentTimeMillis();
  String logParams=logRequest(projectName,callback,startStr,rowsStr,queryStr,dist,fl,groupby,sort,order,leftjoin);
  LOG.info("higorequest:" + cutString(logParams));
  TablePartion part=GetPartions.partion(projectName);
  HeartBeat hb=new HeartBeat(out);
  new Thread(hb).start();
  try {
    queryStr=WebServiceParams.query(queryStr);
    String logParams2=logRequest(projectName,callback,startStr,rowsStr,queryStr,dist,fl,groupby,sort,order,leftjoin);
    LOG.info("query:" + cutString(logParams2));
    int start=WebServiceParams.parseStart(startStr);
    int rows=WebServiceParams.parseRows(rowsStr);
    ArrayList<String> groupbyFields=WebServiceParams.groupFields(groupby);
    ArrayList<String> showFields=WebServiceParams.showFields(fl);
    HashSet<String> commonStatMap=new HashSet<String>();
    HashSet<String> distStatFieldMap=new HashSet<String>();
    WebServiceParams.setCrossStatMap(showFields,commonStatMap,distStatFieldMap);
    Map stormconf=Utils.readStormConfig();
    String mode=String.valueOf(stormconf.get("higo.mode." + part.name));
    LinkedHashMap<String,String> fieldColumntypeMap=readFieldsFromSchemaXml(part.name);
    SortParam sortType=WebServiceParams.sort(sort,order,fieldColumntypeMap,groupbyFields);
    ShardsList[] cores=GetShards.get(part.name,false);
    for (int i=0; i < 10; i++) {
      if (cores.length != StormUtils.parseInt(stormconf.get("higo.shards.count"))) {
        if (i > 5) {
          throw new Exception("core.size=" + cores.length);
        }
        SolrInfoList infolist=GetShards.getSolrInfoList(part.name);
        infolist.run();
        cores=GetShards.get(part.name,false);
        LOG.info("core.size=" + cores.length);
        Thread.sleep(1000);
      }
 else {
        break;
      }
    }
    LOG.info("request core.size=" + cores.length);
    ShardsList[] ms=GetShards.get(part.name,true);
    MdrillPartionsInterface drillpart=MdrillPartions.INSTANCE(part.parttype);
    String[] partionsAll=drillpart.SqlPartions(queryStr);
    queryStr=drillpart.SqlFilter(queryStr);
    Arrays.sort(partionsAll);
    LOG.info("partionsAll:" + cutString(Arrays.toString(partionsAll)));
    GetPartions.Shards shard=GetPartions.getshard(part,partionsAll,cores,ms);
    HigoJoinParams[] joins=WebServiceParams.parseJoins(leftjoin,shard);
    boolean isnothedate=mode.indexOf("@nothedate@") >= 0;
    ArrayList<String> fqList=WebServiceParams.fqList(isnothedate,queryStr,shard,fieldColumntypeMap);
    if (isnothedate && mode.indexOf("@fdt@") < 0) {
      fqList.add("-higoempty_emptydoc_s:[* TO *]");
    }
    String rtn=result(part,callback,fqList,shard,start,rows,sortType,groupbyFields,showFields,commonStatMap,distStatFieldMap,joins,mode);
    long t2=System.currentTimeMillis();
    long timetaken=t2 - t1;
    LOG.info("timetaken:" + (timetaken) + ",logParams2:"+ cutString(logParams2));
    if (timetaken > 1000l * 100) {
      LOG.info("longrequest:" + (timetaken) + ",logParams2:"+ cutString(logParams2)+ "@"+ cutString(rtn));
    }
    hb.setIsstop(true);
    while (!hb.isstop()) {
      try {
        Thread.sleep(100);
      }
 catch (      InterruptedException e) {
      }
    }
synchronized (hb.lock) {
      if (out != null) {
        out.write(rtn);
      }
    }
    return rtn;
  }
 catch (  RuntimeException e) {
    SolrInfoList infolist=GetShards.getSolrInfoList(part.name);
    infolist.run();
    long t2=System.currentTimeMillis();
    LOG.error("timetaken:" + (t2 - t1) + ",logParams:"+ cutString(logParams));
    LOG.error(cutString(logParams),e);
    throw e;
  }
catch (  Exception e) {
    SolrInfoList infolist=GetShards.getSolrInfoList(part.name);
    infolist.run();
    long t2=System.currentTimeMillis();
    LOG.error("timetaken:" + (t2 - t1) + ",logParams:"+ cutString(logParams));
    LOG.error(cutString(logParams),e);
    throw e;
  }
 finally {
    hb.setIsstop(true);
  }
}
