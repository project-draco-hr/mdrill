{
  Vector result=new Vector();
  result.addElement(new Option("\tOutput word counts rather than boolean word presence.\n","C",0,"-C"));
  result.addElement(new Option("\tSpecify list of string attributes to convert to words (as weka Range).\n" + "\t(default: select all string attributes)","R",1,"-R <index1,index2-index4,...>"));
  result.addElement(new Option("\tInvert matching sense of column indexes.","V",0,"-V"));
  result.addElement(new Option("\tSpecify a prefix for the created attribute names.\n" + "\t(default: \"\")","P",1,"-P <attribute name prefix>"));
  result.addElement(new Option("\tSpecify approximate number of word fields to create.\n" + "\tSurplus words will be discarded..\n" + "\t(default: 1000)","W",1,"-W <number of words to keep>"));
  result.addElement(new Option("\tSpecify the rate (e.g., every 10% of the input dataset) at which to periodically prune the dictionary.\n" + "\t-W prunes after creating a full dictionary. You may not have enough memory for this approach.\n" + "\t(default: no periodic pruning)","prune-rate",1,"-prune-rate <rate as a percentage of dataset>"));
  result.addElement(new Option("\tTransform the word frequencies into log(1+fij)\n" + "\twhere fij is the frequency of word i in jth document(instance).\n","T",0,"-T"));
  result.addElement(new Option("\tTransform each word frequency into:\n" + "\tfij*log(num of Documents/num of documents containing word i)\n" + "\t  where fij if frequency of word i in jth document(instance)","I",0,"-I"));
  result.addElement(new Option("\tWhether to 0=not normalize/1=normalize all data/2=normalize test data only\n" + "\tto average length of training documents " + "(default 0=don\'t normalize).","N",1,"-N"));
  result.addElement(new Option("\tConvert all tokens to lowercase before " + "adding to the dictionary.","L",0,"-L"));
  result.addElement(new Option("\tIgnore words that are in the stoplist.","S",0,"-S"));
  result.addElement(new Option("\tThe stemmering algorihtm (classname plus parameters) to use.","stemmer",1,"-stemmer <spec>"));
  result.addElement(new Option("\tThe minimum term frequency (default = 1).","M",1,"-M <int>"));
  result.addElement(new Option("\tIf this is set, the maximum number of words and the \n" + "\tminimum term frequency is not enforced on a per-class \n" + "\tbasis but based on the documents in all the classes \n"+ "\t(even if a class attribute is set).","O",0,"-O"));
  result.addElement(new Option("\tA file containing stopwords to override the default ones.\n" + "\tUsing this option automatically sets the flag ('-S') to use the\n" + "\tstoplist if the file exists.\n"+ "\tFormat: one stopword per line, lines starting with '#'\n"+ "\tare interpreted as comments and ignored.","stopwords",1,"-stopwords <file>"));
  result.addElement(new Option("\tThe tokenizing algorihtm (classname plus parameters) to use.\n" + "\t(default: " + WordTokenizer.class.getName() + ")","tokenizer",1,"-tokenizer <spec>"));
  return result.elements();
}
