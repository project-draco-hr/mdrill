{
  try {
    checkTopologyActive(data,topologyname,false);
  }
 catch (  NotAliveException e) {
    LOG.info(e.get_msg());
  }
  data.getSubmittedCount().incrementAndGet();
  String topologyId=topologyname + "-" + data.getSubmittedCount().get()+ "-"+ TimeUtils.current_time_secs();
  Map<Object,Object> serializedConf=(Map<Object,Object>)StormUtils.from_json(jsonConf);
  if (serializedConf == null) {
    serializedConf=new HashMap<Object,Object>();
  }
  serializedConf.put(Config.STORM_ID,topologyId);
  Map<Object,Object> stormConf=NimbusUtils.normalizeConf(conf,serializedConf,topology);
  Map<Object,Object> totalStormConf=new HashMap<Object,Object>(conf);
  totalStormConf.putAll(stormConf);
  totalStormConf.putAll(serializedConf);
  StormTopology newtopology=new StormTopology(topology);
  StormClusterState stormClusterState=data.getStormClusterState();
  Common.system_topology(totalStormConf,newtopology);
  LOG.info("Received topology submission for " + topologyname + " with conf "+ serializedConf);
synchronized (data.getSubmitLock()) {
    try {
      setupStormCode(conf,topologyId,uploadedJarLocation,serializedConf,newtopology);
      stormClusterState.setup_heartbeats(topologyId);
      setupStormStatic(conf,topologyId,stormClusterState);
      NimbusUtils.mkAssignments(data,topologyId);
      startTopology(topologyname,stormClusterState,topologyId);
    }
 catch (    IOException e) {
      LOG.info("setupStormCode stormId: " + topologyId + " uploadedJarLocation: "+ uploadedJarLocation+ "failed; OR"+ "mkAssignments stormId: "+ topologyId+ " failed!");
    }
  }
}
