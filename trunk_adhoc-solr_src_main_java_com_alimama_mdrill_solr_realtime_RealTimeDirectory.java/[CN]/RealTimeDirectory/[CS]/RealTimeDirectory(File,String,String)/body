{
  LOG.info("####" + path.getAbsolutePath() + ","+ hdfsPath);
  this.hadoopConfDir=hadoopConfDir;
  this.baseDir=path.getAbsolutePath();
  this.hdfsPath=hdfsPath;
  Configuration conf=this.getConf();
  FileSystem fs=FileSystem.get(conf);
  fs.mkdirs(new Path(hdfsPath).getParent());
  path.mkdirs();
  File links=new File(path,"indexLinks");
  if (links.exists()) {
    FileReader freader=new FileReader(links);
    BufferedReader br=new BufferedReader(freader);
    String s1=null;
    while ((s1=br.readLine()) != null) {
      if (s1.trim().length() > 0) {
        if (s1.startsWith("@hdfs@")) {
          Path p=new Path(s1.replaceAll("@hdfs@",""));
          if (!fs.exists(p)) {
            continue;
          }
          Path p2=new Path(p.getParent(),"sigment/" + p.getName());
          if (fs.exists(p2)) {
            FileStatus[] sublist=fs.listStatus(p2);
            if (sublist == null) {
              continue;
            }
            for (            FileStatus ssss : sublist) {
              FileSystemDirectory d=new FileSystemDirectory(fs,ssss.getPath(),false,conf);
              DirectoryInfo info=new DirectoryInfo();
              info.d=d;
              info.tp=DirectoryInfo.DirTpe.file;
              diskDirector.put(s1 + "/sigment/" + ssss.getPath().getName(),info);
              ishdfsmode=true;
              SolrCore.log.info(">>>>>FileSystemDirectory hdfs add links " + ssss.getPath());
            }
          }
 else {
            FileSystemDirectory d=new FileSystemDirectory(fs,p,false,conf);
            DirectoryInfo info=new DirectoryInfo();
            info.d=d;
            info.tp=DirectoryInfo.DirTpe.file;
            diskDirector.put(s1,info);
            ishdfsmode=true;
            SolrCore.log.info(">>>>>FileSystemDirectory readOnlyOpen add links " + s1);
          }
        }
        File f=new File(s1);
        if (!f.exists()) {
          continue;
        }
        FSDirectory d=LinkFSDirectory.open(f);
        DirectoryInfo info=new DirectoryInfo();
        info.d=d;
        info.tp=DirectoryInfo.DirTpe.file;
        diskDirector.put(s1,info);
        SolrCore.log.info(">>>>>LinkFSDirectory readOnlyOpen add links " + s1);
      }
    }
    br.close();
    freader.close();
  }
  _cleaner=new Thread(new Runnable(){
    public void run(){
      if (RealTimeDirectory.this.ishdfsmode) {
        return;
      }
      while (true) {
        try {
          Thread.sleep(UniqConfig.RealTimeHdfsFlush() * 1000l);
          RealTimeDirectory.this.syncHdfs();
        }
 catch (        InterruptedException ex) {
        }
      }
    }
  }
);
  _cleaner.setDaemon(true);
  _cleaner.start();
  _doclistthr=new Thread(new Runnable(){
    public void run(){
      if (RealTimeDirectory.this.ishdfsmode) {
        return;
      }
      long lasttime=System.currentTimeMillis();
      long tslen=UniqConfig.RealTimeDoclistFlush() * 1000l;
      while (true) {
        try {
          Thread.sleep(1000l);
          int size=0;
synchronized (RealTimeDirectory.this.doclistBuffer_lock) {
            size=RealTimeDirectory.this.doclistBuffer.size();
          }
          long nowtime=System.currentTimeMillis();
          if (size == 0) {
            continue;
          }
          if (size >= UniqConfig.RealTimeDoclistBuffer() || (lasttime + tslen) < nowtime) {
            RealTimeDirectory.this.flushDocList();
            lasttime=System.currentTimeMillis();
            long ts=lasttime - nowtime;
            LOG.info("flushDocList timetake:" + (ts / 1000) + RealTimeDirectory.this.extaLog());
          }
        }
 catch (        Throwable ex) {
        }
      }
    }
  }
);
  _doclistthr.setDaemon(true);
  _doclistthr.start();
}
