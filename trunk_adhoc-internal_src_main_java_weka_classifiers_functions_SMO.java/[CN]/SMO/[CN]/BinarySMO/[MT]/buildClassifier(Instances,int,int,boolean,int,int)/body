{
  m_bUp=-1;
  m_bLow=1;
  m_b=0;
  m_alpha=null;
  m_data=null;
  m_weights=null;
  m_errors=null;
  m_logistic=null;
  m_I0=null;
  m_I1=null;
  m_I2=null;
  m_I3=null;
  m_I4=null;
  m_sparseWeights=null;
  m_sparseIndices=null;
  m_sumOfWeights=insts.sumOfWeights();
  m_class=new double[insts.numInstances()];
  m_iUp=-1;
  m_iLow=-1;
  for (int i=0; i < m_class.length; i++) {
    if ((int)insts.instance(i).classValue() == cl1) {
      m_class[i]=-1;
      m_iLow=i;
    }
 else     if ((int)insts.instance(i).classValue() == cl2) {
      m_class[i]=1;
      m_iUp=i;
    }
 else {
      throw new Exception("This should never happen!");
    }
  }
  if ((m_iUp == -1) || (m_iLow == -1)) {
    if (m_iUp != -1) {
      m_b=-1;
    }
 else     if (m_iLow != -1) {
      m_b=1;
    }
 else {
      m_class=null;
      return;
    }
    if (m_KernelIsLinear) {
      m_sparseWeights=new double[0];
      m_sparseIndices=new int[0];
      m_class=null;
    }
 else {
      m_supportVectors=new SMOset(0);
      m_alpha=new double[0];
      m_class=new double[0];
    }
    if (fitLogistic) {
      fitLogistic(insts,cl1,cl2,numFolds,new Random(randomSeed));
    }
    return;
  }
  m_data=insts;
  if (m_KernelIsLinear) {
    m_weights=new double[m_data.numAttributes()];
  }
 else {
    m_weights=null;
  }
  m_alpha=new double[m_data.numInstances()];
  m_supportVectors=new SMOset(m_data.numInstances());
  m_I0=new SMOset(m_data.numInstances());
  m_I1=new SMOset(m_data.numInstances());
  m_I2=new SMOset(m_data.numInstances());
  m_I3=new SMOset(m_data.numInstances());
  m_I4=new SMOset(m_data.numInstances());
  m_sparseWeights=null;
  m_sparseIndices=null;
  m_kernel.buildKernel(m_data);
  m_errors=new double[m_data.numInstances()];
  m_errors[m_iLow]=1;
  m_errors[m_iUp]=-1;
  for (int i=0; i < m_class.length; i++) {
    if (m_class[i] == 1) {
      m_I1.insert(i);
    }
 else {
      m_I4.insert(i);
    }
  }
  int numChanged=0;
  boolean examineAll=true;
  while ((numChanged > 0) || examineAll) {
    numChanged=0;
    if (examineAll) {
      for (int i=0; i < m_alpha.length; i++) {
        if (examineExample(i)) {
          numChanged++;
        }
      }
    }
 else {
      for (int i=0; i < m_alpha.length; i++) {
        if ((m_alpha[i] > 0) && (m_alpha[i] < m_C * m_data.instance(i).weight())) {
          if (examineExample(i)) {
            numChanged++;
          }
          if (m_bUp > m_bLow - 2 * m_tol) {
            numChanged=0;
            break;
          }
        }
      }
    }
    if (examineAll) {
      examineAll=false;
    }
 else     if (numChanged == 0) {
      examineAll=true;
    }
  }
  m_b=(m_bLow + m_bUp) / 2.0;
  m_kernel.clean();
  m_errors=null;
  m_I0=m_I1=m_I2=m_I3=m_I4=null;
  if (m_KernelIsLinear) {
    m_supportVectors=null;
    m_class=null;
    if (!m_checksTurnedOff) {
      m_data=new Instances(m_data,0);
    }
 else {
      m_data=null;
    }
    double[] sparseWeights=new double[m_weights.length];
    int[] sparseIndices=new int[m_weights.length];
    int counter=0;
    for (int i=0; i < m_weights.length; i++) {
      if (m_weights[i] != 0.0) {
        sparseWeights[counter]=m_weights[i];
        sparseIndices[counter]=i;
        counter++;
      }
    }
    m_sparseWeights=new double[counter];
    m_sparseIndices=new int[counter];
    System.arraycopy(sparseWeights,0,m_sparseWeights,0,counter);
    System.arraycopy(sparseIndices,0,m_sparseIndices,0,counter);
    m_weights=null;
    m_alpha=null;
  }
  if (fitLogistic) {
    fitLogistic(insts,cl1,cl2,numFolds,new Random(randomSeed));
  }
}
