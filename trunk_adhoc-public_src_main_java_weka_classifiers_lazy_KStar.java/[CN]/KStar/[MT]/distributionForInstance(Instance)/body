{
  String debug="(KStar.distributionForInstance) ";
  double transProb=0.0, temp=0.0;
  double[] classProbability=new double[m_NumClasses];
  double[] predictedValue=new double[1];
  for (int i=0; i < classProbability.length; i++) {
    classProbability[i]=0.0;
  }
  predictedValue[0]=0.0;
  if (m_InitFlag == ON) {
    if (m_BlendMethod == B_ENTROPY) {
      generateRandomClassColomns();
    }
    m_Cache=new KStarCache[m_NumAttributes];
    for (int i=0; i < m_NumAttributes; i++) {
      m_Cache[i]=new KStarCache();
    }
    m_InitFlag=OFF;
  }
  Instance trainInstance;
  Enumeration enu=m_Train.enumerateInstances();
  while (enu.hasMoreElements()) {
    trainInstance=(Instance)enu.nextElement();
    transProb=instanceTransformationProbability(instance,trainInstance);
switch (m_ClassType) {
case Attribute.NOMINAL:
      classProbability[(int)trainInstance.classValue()]+=transProb;
    break;
case Attribute.NUMERIC:
  predictedValue[0]+=transProb * trainInstance.classValue();
temp+=transProb;
break;
}
}
if (m_ClassType == Attribute.NOMINAL) {
double sum=Utils.sum(classProbability);
if (sum <= 0.0) for (int i=0; i < classProbability.length; i++) classProbability[i]=(double)1 / (double)m_NumClasses;
 else Utils.normalize(classProbability,sum);
return classProbability;
}
 else {
predictedValue[0]=(temp != 0) ? predictedValue[0] / temp : 0.0;
return predictedValue;
}
}
